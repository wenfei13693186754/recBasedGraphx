package com.wdcloud.graphx.recommend

import java.io.File
import java.io.FileOutputStream
import java.io.PrintStream
import java.io.Serializable
import org.apache.spark.graphx.VertexId
import org.apache.spark.SparkContext
import org.apache.spark.graphx.Edge
import org.apache.spark.graphx.Graph
import org.apache.spark.graphx.VertexRDD
import org.apache.spark.rdd.RDD
import org.apache.spark.storage.StorageLevel

import com.wdcloud.graphx.kafka.Producer
import com.wdcloud.graphx.unit.DataToJson

import akka.event.slf4j.Logger
import org.apache.spark.SparkConf
import com.wdcloud.graphx.unit.PregelUtil
import org.apache.spark.graphx.EdgeDirection
import com.wdcloud.graphx.unit.CreateSubGraph
import com.wdcloud.graphx.unit.UserIdToLong

/**
 * 使用spark-graphx实现基于好友、圈子来实现推荐二度好友、圈子、物品
 * 		要求：1.离线的、全量的；
 * 				 2.各种关系基于不同权重进行推荐
 *
 * jobserver调用
 *
 */
object RecEngBySubGraph extends Serializable {

  val logger = Logger(this.getClass.getName)
  
  def startRecEntry(
    sc: SparkContext,
    namespace: String,
    edgeTable: String,  
    pAttrTable: String,
    iAttrTable: String,
    userIdListStr: List[String]
  ){  
    logger.warn("startRecEntry用户业务id是："+userIdListStr.toString());
    //将用户的业务id转化为long类型的id
    val userIdListLong = UserIdToLong.userIdToLong(userIdListStr) 
    //创建图
    val t0 = System.currentTimeMillis()
    val vertices = sc.objectFile[(Long, Map[String, Object])]("hdfs://192.168.6.84:9000/graph/vertices")
    val edges = sc.objectFile[Edge[Double]]("hdfs://192.168.6.84:9000/graph/edges")
    val graph = Graph(vertices, edges)
    val subGraph = CreateSubGraph.createSubGraph(graph, userIdListLong)
    
    logger.warn("全图顶点数："+graph.vertices.count()+"||子图顶点数："+subGraph.vertices.count()+"全图边数："+graph.edges.count()+"子图边数："+subGraph.edges.count())
    
    val recCode = new RecCode(subGraph, namespace)
    val recResult = recCode.recForUsers(userIdListStr)
    
    //将结果转化为json格式
    val jsonResult = DataToJson.recResultRDDToJson(recResult).cache()

    //将结果放到kafka中
    val kafkaProducer = Producer.sendMsgToKafka(jsonResult, namespace)
    val t1 = System.currentTimeMillis()
    logger.warn("基于子图合并推荐结果结束,用时："+(t1-t0))
    val fs = new FileOutputStream(
    		new File("/wdcloud/app/spark/data/rec_jobserver_result/recResultBySubGraph.log"));
    val p = new PrintStream(fs);
    recResult.collect().foreach(x => p.println(s"用户 ${x._1} 的推荐结果是：${x._2}***${x._3.mkString(",")}"))
    logger.warn("基于子图的推荐结束")
  }
}

