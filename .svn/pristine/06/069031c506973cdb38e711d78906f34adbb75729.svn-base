package com.wdcloud.graphx.modelTraining.graph

import scala.Iterator

import org.apache.spark.graphx.EdgeDirection
import org.apache.spark.graphx.EdgeTriplet
import org.apache.spark.graphx.Graph
import org.apache.spark.graphx.VertexId
import org.apache.spark.rdd.RDD
import org.apache.spark.rdd.RDD.rddToPairRDDFunctions

import com.wdcloud.graphx.environmentContext.DataContext
import com.wdcloud.graphx.modelTraining.Recommender
import com.wdcloud.graphx.modelTraining.graph.util.GraphResultHandle
import com.wdcloud.graphx.scalaUtil.PregelUtil

import akka.event.slf4j.Logger
import org.apache.spark.broadcast.Broadcast
import org.apache.spark.SparkContext
import com.wdcloud.graphx.modelBuild.graph.ReadData

/**
 * 进行基于二度好友的推荐
 * 	向每个用户推荐他的直接关系好友所关系的物品，但是他没关系的物品
 */
class TwoDegreesFriendsRecommender(userConf: Map[String, String]) extends Recommender(userConf) {   
  val logger = Logger(this.getClass.getName)
  var middleResult: RDD[(VertexId, Map[Long, List[(Long, Double)]])] = null   
     
  /*
   * 基于一度好友推荐好友、物、圈子  
   * 使用pregel，迭代两次，第一次dst顶点发送消息给src顶点，第二次dst顶点发送它收到的第一次迭代的消息给src顶点
   * 迭代次数使用自定义的PregelUtil中的iterNum来判定  
   * 	iterNum初始值是0，每执行一次迭代增加1
   * vprog:
   * 		1.初始化：初始化信息是 List[(VertexId, (String, Double, String))]()，vprog函数收到这个信息后，给每个顶点添加rec->Map[String, List[(VertexId, Double, String)]]()属性，用来存放结果
   * 		2.第一次迭代收到的消息是 List[(VertexId, (type, Double, 业务id))]((...))，将其放在key是rec的位置；
   * 		3.第二次迭代收到的消息是List[(VertexId, (type, Double, 业务id))]((...))，将其放在key的位置上；
   * 			这个时候要对数组进行处理：包括对相同VertexId的数据进行分数累加去重和分组，最后的处理结果格式是：Map[String, List[(VertexId, Double, String)]]
   * 
   * sendMsg：
   * 		1.第一次迭代：发送 List[(VertexId, (type, Double, 业务id))]((...))给src顶点
   * 		2.第二次迭代：限定只有收到第一次迭代消息的顶点才可以发送消息（发送消息的方向设置为IN），发送的消息是第一次迭代收到的消息；
   * 				第二次发送数据时候，要将第一次迭代收到的消息中的分数乘上当前triplet上的score作为最终的score
   * 
   * mergeMsg：  
   * 		1.第一次迭代，收到的消息是List[(VertexId, (type, Double, 业务id))]((...))，将这些消息使用.:::合并为一个List
   * 		2.第二次迭代，收到的消息是List[(VertexId, (type, Double, 业务id))]((...))，将这些消息使用.:::合并为一个List
   * 
   * 返回值类型是：RDD[(Int, Long, Map[Int, List[(Long, Double)]])]-->RDD[(命名空间, 顶点id, Map[Int, List[(Long, Double)]])]
   */
  val simPregel = new PregelUtil()
  override def predict(sc: SparkContext, graphModel: Graph[Map[Int, Any], Double]): RDD[(Int, Long, Map[Long, List[(Long, Double)]])] = {
    val graph = sc.broadcast(graphModel)
    //读取配置信息
    val namespace = userConf.get("namespace").get  
    
    //调用自定义的PregelUtil方法执行pregel迭代操作
    val g2 = simPregel.apply(graph.value, List[(VertexId, (Long, Double))](), 2, EdgeDirection.In)(vprog, sendMsg, merge)  
    middleResult = GraphResultHandle.recResultHandle(g2)  
    val recResult = middleResult.reduceByKey((x, y) => GraphResultHandle.mapCombine(x, y)).map(x => (1, x._1, x._2))
    logger.warn("基于二度好友的推荐成功")  
    
    recResult 
  }
 
  /**
   * 基于好友推荐的merge函数
   */
  private def merge(list1: List[(VertexId, (Long, Double))], list2: List[(VertexId, (Long, Double))]): List[(VertexId, (Long, Double))] = {
    val list = list1.:::(list2)
    list
  }

  /**  
   * 基于好友推荐的vprog函数
   */
  private def vprog(vId: VertexId, oldAttr: Map[Int, Any], newAttr: List[(VertexId, (Long, Double))]): Map[Int, Any] = {
    val attrID: Int = ReadData.pointAttrMap.get("rec").get
    if (newAttr.size == 0) { //初始化
      oldAttr.+(attrID-> Map[Int, List[(Long, Double)]]())//Map[被推荐物品的类型, List[(物品的innerId, Score)]]()
    } else if (simPregel.iterNum == 1) { //第一次迭代,收到的信息格式：List[(VertexId, (Long, Double))]

      oldAttr.updated(attrID, newAttr)
    } else if (simPregel.iterNum == 2) { //第二次迭代,收到的信息格式：List[(VertexId, (Long, Double))]-->List[(被推荐物品hash后的id,, (类型, score))]
      val dealData = GraphResultHandle.finallyPointResultHandle(oldAttr, newAttr, vId) 
      oldAttr.updated(attrID, dealData)   
    } else {

      oldAttr
    }
  }

  /**
   * 基于好友推荐的sendMsg函数
   */
  private def sendMsg(triplet:  EdgeTriplet[Map[Int, Any], Double]): Iterator[(Long, List[(VertexId, (Long, Double))])] = {
    if (simPregel.iterNum == 0) { //第一次迭代发送的数据格式：List[(VertexId, (Int, Double))]-->List[(被推荐物品hash后的id, (类型, Double))]
      val dstAttr = triplet.dstAttr
      Iterator((triplet.srcId, List[(VertexId, (Long, Double))]((triplet.dstId, (dstAttr.apply(1).asInstanceOf[Long], triplet.attr)))))
    } else { //第二次迭代,限定只有收到第一次迭代消息的顶点才可以发送消息（发送消息的方向设置为IN），发送的消息是第一次迭代收到的消息；
      val dstAttr = triplet.dstAttr
      //第二次发送数据时候，要将第一次迭代收到的消息中的分数乘上当前triplet上的score作为最终的score
      if (dstAttr.apply(3).isInstanceOf[List[(VertexId, (Long, Double))]]) {
        val itera1 = dstAttr.apply(3).asInstanceOf[List[(VertexId, (Long, Double))]] //取出每个dst顶点上的map中的3(“rec”)键对应的value，类型是：List[(VertexId, (Int, Double))],分别代表id和类别以及score类型的数组
        val itera2 = itera1.map(x => (x._1, (x._2._1, x._2._2 * triplet.attr)))

        //将第一次迭代顶点收到的消息置为空，以腾出内存空间  
        dstAttr.updated(3, Map[Int, List[(Long, Double)]]())

        Iterator((triplet.srcId, itera2))
      } else {
        Iterator.empty
      }
    }
  }

}