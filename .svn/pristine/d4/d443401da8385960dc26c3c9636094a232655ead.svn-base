package com.wdcloud.graphx.graphOperate

import java.io.Serializable

import scala.Iterator
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.graphx.Edge
import org.apache.spark.graphx.EdgeDirection
import org.apache.spark.graphx.EdgeTriplet
import org.apache.spark.graphx.Graph
import org.apache.spark.graphx.Graph.graphToGraphOps
import org.apache.spark.graphx.TripletFields
import org.apache.spark.graphx.VertexId
import org.apache.spark.rdd.RDD
import org.apache.spark.rdd.RDD.rddToPairRDDFunctions

import com.google.common.hash.Hashing
import com.wdcloud.graphx.unit.DataToJson
import com.wdcloud.graphx.kafka.Producer
import com.wdcloud.graphx.hbase.SparkHbase
import org.apache.hadoop.hbase.HBaseConfiguration
import org.apache.hadoop.hbase.client.HBaseAdmin
import org.apache.hadoop.hbase.client.HTable
import org.apache.hadoop.hbase.client.Put
import org.apache.hadoop.hbase.client.Result
import org.apache.hadoop.hbase.io.ImmutableBytesWritable
import org.apache.hadoop.hbase.mapreduce.TableInputFormat
import org.apache.hadoop.hbase.util.Bytes

 import akka.event.slf4j.Logger
import scala.collection.immutable.Seq
import org.apache.hadoop.hbase.client.Get
import org.apache.hadoop.hbase.client.Scan

object RecCode extends Serializable{
   val sc = OperateSparkContext.init()
   val logger = Logger(this.getClass.getName)   
    /*
   * 基于圈子对用户进行全量推荐好友、物品和圈子
   * 步骤如下：首先所有顶点发送信息给src顶点，也就是user顶点，user顶点收到消息后将该消息以kv形式保存到map属性中；然后第二次迭代user顶点发送它们收到的消息和它们自己的属性给圈子顶点，
   * 圈子顶点收到消息后做去重和排序后以kv形式保存到map属性中；最后第三次迭代圈子顶点将收到的消息发送到user顶点。user顶点收到消息后从消息中去除掉自己直接关系的顶点信息，作为最终的推荐结果。
   * 其间要将图上的hash后的id值转化为业务id后作为处理结果返回。
   * 详细如下
   * 1.使用pregel，初始化信息使用每次迭代发送的消息格式，是Array[(VertexId, (String, Double,String))]()，一个空的数组，迭代三次，消息发送方向是任意(either)
   * 		1.初始化的时候，给每个顶点做标记“three”,表示进行初始化了，每个顶点生命值是three
   * 		2.第一次迭代，向src顶点，也就是用户顶点，发送dst的属性，格式是Array[(VertexId, (String, Double,String))]()。发送的时候sendMsg限定各个顶点的生命值是three，用来确定是第一次迭代，
   * 然后vprog函数先判断当前顶点生命值是three，以确定是第一次迭代，然后在进行消息聚合后，将用户顶点生命值改为two;
   * 		3.第二次迭代，sendMsg限定src顶点生命值是two，dst顶点生命值是three，并且限定dst顶点类型是circle，作用是只向圈子顶点发送消息；然后发送Array[(VertexId, (String, Double))]()
   * 格式的第一次迭代时候发送到各个src顶点的消息；vprog函数先判断是第二次迭代，然后聚合消息，并将顶点生命值减1；
   * 		4.第三次迭代，sendMsg先判断是第三次迭代，然后将第二次迭代收到的消息发送到src顶点；然后vprog函数判断是第三次迭代，之后将数据进行去重，分组放到属性map中
   * 2.对保存到每个用户顶点上的推荐结果，去除掉用户直接关系的顶点，作为最终的推荐结果。
   * 
   * 3.返回的结果：RDD[(String, String, Map[String, List[(String, Double)]])]-->RDD[(命名空间名称, 用户的业务id, Map[推荐物品类型, List[(推荐物品业务id, score)]])]
   */
  def recICUForUserBasedCircle1(graph: Graph[Map[String, Object], Double]): RDD[(VertexId, (String, Map[String, List[(String, Double)]]))] = {
    logger.warn("基于圈子的推荐使用的线程是：" + Thread.currentThread().getName)
    val t0 = System.currentTimeMillis()
    val g1 = graph.pregel(Array[(VertexId, (String, Double, String))](), 3, EdgeDirection.Either)(
      (id, oldAttr, newAttr) =>
        if (newAttr.length == 0) { //初始化信息合并方式
          //将声明值减1，然后在每个顶点上添加key是rec属性
          oldAttr.updated("life", ((oldAttr.apply("life").asInstanceOf[String]).toInt - 1) + "").+("rec" -> Map[String, List[(VertexId, Double, String)]]())
        } else if (oldAttr.apply("type").asInstanceOf[String].equals("person") && oldAttr.apply("life").asInstanceOf[String].toInt == 2) { //第一次迭代，圈子直接关系用户的邻居信息的聚合
          oldAttr.updated("life", ((oldAttr.apply("life").asInstanceOf[String]).toInt - 1) + "").+("rec" -> newAttr) //用户顶点生命值减1，并将收到的信息放到属性map中
        } else if (oldAttr.apply("type").asInstanceOf[String].equals("circle") && oldAttr.apply("life").asInstanceOf[String].toInt == 2) { //第二次迭代，圈子信息的聚合
          oldAttr.updated("life", ((oldAttr.apply("life").asInstanceOf[String]).toInt - 1) + "").+("rec" -> newAttr) //将圈子顶点的生命值减一，最后将得到的信息保存到属性map中
        } else if (oldAttr.apply("life").asInstanceOf[String].toInt == 1 && oldAttr.apply("type").asInstanceOf[String].equals("person")) { //第三次迭代，将圈子上的推荐信息聚合到圈子的直接关系用户上
          logger.warn("recBasedCircle newAttr: "+newAttr.mkString(","))
          val newAttrRdd = sc.parallelize(newAttr) //RDD[(VertexId, (String, Double, String))]-->RDD[(hash后id, (类型, score, 业务id))]
          //对数据进行去重，分组，分组后数据格式是：RDD[(String, Iterable[(VertexId, (String, Double, String))])]-->RDD[(被推荐物品类型, Iterable[(VertexId, (被推荐物品类型, score, 被推荐物品业务id))])]
          val filterData = newAttrRdd.map(x => (x._1, x._2)).reduceByKey((x, y) => (x._1, x._2 + y._2, x._3)).groupBy(x => x._2._1)
          //对数据格式进行重新整理,整理后数据是：Map[String, List[(VertexId, Double, String)]]-->Map[type, List[(hash后id, score, 业务id)]]
          //期望：格式是：Map[]
          val dealData = filterData.map { x =>
            (x._1, x._2.map(x => (x._2._3, x._2._2)).toList)
          }.collect().toMap
          oldAttr.updated("rec", dealData) //将得到的信息保存到map中
        } else {
          oldAttr
        },
      triplet =>
        if (triplet.srcAttr.apply("life").asInstanceOf[String].toInt == 1 && triplet.dstAttr.apply("life").asInstanceOf[String].toInt == 2 && triplet.dstAttr.apply("type").asInstanceOf[String].equals("circle")) { //第二次迭代，开始发送消息到圈子顶点了
          //获取到圈子的一度用户和用户的下一级直接关系物品的亲密度score，格式是:Array[(VertexId, (String, Double))]，乘上圈子和直接用户的score作为圈子二度关系物品的得分
          //然后重新组成字符串发送到圈子节点上
          val attr = triplet.srcAttr.apply("rec").asInstanceOf[Array[(VertexId, (String, Double, String))]].map { x =>
            val score = x._2._2 * triplet.attr.toDouble
            (x._1, (x._2._1, score, x._2._3))
          }

          //因为基于圈子给用户推荐好友，圈子的直接关系用户被推荐给圈子的另一个用户的概率理论会远远大于，圈子的二度用户，所以这里将圈子的直接关系用户顶点添加到发送的消息中
          val userInfo: Array[(VertexId, (String, Double, String))] = Array((triplet.srcId, (triplet.srcAttr.apply("type").asInstanceOf[String], triplet.attr, triplet.srcAttr.apply("businessId").asInstanceOf[String])))
          //将圈子的直接关系用户顶点信息追加到attr上
          val circleInfo = attr.++:(userInfo)
          Iterator((triplet.dstId, circleInfo))
        } else if (triplet.dstAttr.apply("life").asInstanceOf[String].toInt == 1 && triplet.srcAttr.apply("life").asInstanceOf[String].toInt == 1 && triplet.dstAttr.apply("type").asInstanceOf[String].equals("circle")) { //第三次迭代，将圈子上的推荐信息聚合到圈子直接相关的人上
          Iterator((triplet.srcId, triplet.dstAttr.apply("rec").asInstanceOf[Array[(VertexId, (String, Double, String))]]))
        } else if (triplet.srcAttr.apply("life").asInstanceOf[String].toInt == 2 && triplet.dstAttr.apply("life").asInstanceOf[String].toInt == 2) { //初始化后第一次迭代
          Iterator((triplet.srcId, Array((triplet.dstId, (triplet.dstAttr.apply("type").asInstanceOf[String], triplet.attr, triplet.dstAttr.apply("businessId").asInstanceOf[String])))))
        } else {
          Iterator.empty
        },
      (a, b) => a.++:(b))
    val t1 = System.currentTimeMillis()
    logger.warn("基于圈子的pregel三次迭代操作用时："+(t1-t0))
    val pointData = g1.vertices.filter(x => x._2.apply("type").asInstanceOf[String].equals("person"))
      .map { x =>
        var recData = Map[String, List[(String, Double)]]()
        if (x._2.apply("rec").isInstanceOf[Map[String, List[(String, Double)]]]) {
          recData = x._2.apply("rec").asInstanceOf[Map[String, List[(String, Double)]]]
        } else {
          recData = Map[String, List[(String, Double)]]()
        }
        (x._1, (x._2.apply("businessId").asInstanceOf[String], recData))
      }
    pointData
  }

  /*
   * 基于一度好友推荐好友、物、圈子
   * 使用pregel，迭代两次，第一次dst顶点发送消息给src顶点，第二次dst顶点发送它收到的第一次迭代的消息给src顶点
   * vprog:
   * 		1.初始化：初始化信息是 Array[(VertexId, (String, Double, String))]()，vprog函数收到这个信息后，给图的每个顶点上添加life->2属性,然后给每个顶点添加rec->Map[String, List[(VertexId, Double, String)]]()属性，用来存放结果
   * 		2.第一次迭代收到的消息是 Array[(VertexId, (type, Double, 业务id))]((...))，将其放在key是rec的位置；
   * 		3.第二次迭代收到的消息是Array[(VertexId, (type, Double, 业务id))]((...))，将其放在key的位置上；
   * 			这个时候要对数组进行处理：包括对相同VertexId的数据进行分数累加去重和分组，最后的处理结果格式是：Map[String, List[(VertexId, Double, String)]]
   * 
   * sendMsg：
   * 		1.第一次迭代：发送 Array[(VertexId, (type, Double, 业务id))]((...))给src顶点
   * 		2.第二次迭代：限定只有收到第一次迭代消息的顶点才可以发送消息（发送消息的方向设置为IN），发送的消息是第一次迭代收到的消息；
   * 				第二次发送数据时候，要将第一次迭代收到的消息中的分数乘上当前triplet上的score作为最终的score
   * 
   * mergeMsg：
   * 		1.第一次迭代，收到的消息是Array[(VertexId, (type, Double, 业务id))]((...))，将这些消息使用.++合并为一个Array
   * 		2.第二次迭代，收到的消息是Array[(VertexId, (type, Double, 业务id))]((...))，将这些消息使用.++合并为一个Array
   * 两次迭代完成后，图的每个顶点上的属性中都有key是num2，value是二度关系顶点的一个属性，然后开始进行去重，去除掉属性中包含了用户直接关系顶点的信息
   * 
   * 返回值类型是：RDD[(String, Map[String, List[(String, Double)]])]
   */
  def recBasedSimUser(graph: Graph[Map[String, Object], Double]): RDD[(VertexId, (String, Map[String, List[(String, Double)]]))] = {
    logger.warn("基于好友的推荐使用的线程是：" + Thread.currentThread().getName)
    val t0 = System.currentTimeMillis()
    val g2 = graph.pregel(Array[(VertexId, (String, Double, String))](), 2, EdgeDirection.In)(
      (vid, oldAttr, newAttr) =>
        //每调用一次该方法，那么life生命值减1,初始值是3
        if (newAttr.size == 0) { //初始化
          oldAttr.updated("life", ((oldAttr.apply("life").asInstanceOf[String]).toInt - 1) + "").+("rec" -> Map[String, List[(String, Double)]]())
        } else if ((oldAttr.apply("life").asInstanceOf[String]).toInt == 2) { //第一次迭代,收到的信息格式：Array[(VertexId, (String, Double, String))]
          oldAttr.updated("life", ((oldAttr.apply("life").asInstanceOf[String]).toInt - 1) + "").updated("rec", newAttr)
        } else if ((oldAttr.apply("life").asInstanceOf[String]).toInt == 1) { //第二次迭代,收到的信息格式：Array[(VertexId, (String, Double, String))]-->Array[(被推荐物品hash后的id,, (类型, Double, 业务id))]
          //这个时候要对数组进行处理：包括对相同VertexId的数据进行分数累加去重和分组,最终存储的格式是：Map[type, List[(VertexId, Double, 业务id)]]
          logger.warn("recBasedSimUser newAttr: "+newAttr.mkString(","))
          val dealData = sc.parallelize(newAttr).reduceByKey((x, y) => (x._1, x._2 + y._2, x._3)).groupBy(x => x._2._1).map(x => (x._1, (x._2.map(y => (y._2._3, y._2._2)).toList))).collect().toMap
          oldAttr.updated("rec", dealData)
        } else {
          oldAttr
        },
      triplet =>
        //logger.warn("sendMsg生命值："+(triplet.srcAttr.apply("life").toString()).toInt)
        //每次调用sendMsg方法，都对相应的dstId顶点上的属性6减一，用来表示这个顶点迭代的次数
        if ((triplet.srcAttr.apply("life").asInstanceOf[String]).toInt == 2) { //第一次迭代发送的数据格式：Array[(VertexId, (String, Double, String))]-->Array[(被推荐物品hash后的id, (类型, Double, 业务id))]
          Iterator((triplet.srcId, Array[(VertexId, (String, Double, String))]((triplet.dstId, (triplet.dstAttr.apply("type").asInstanceOf[String], triplet.attr, triplet.dstAttr.apply("businessId").asInstanceOf[String])))))
        } else { //第二次迭代,限定只有收到第一次迭代消息的顶点才可以发送消息（发送消息的方向设置为IN），发送的消息是第一次迭代收到的消息；
          //第二次发送数据时候，要将第一次迭代收到的消息中的分数乘上当前triplet上的score作为最终的score
          if (triplet.dstAttr.apply("rec").isInstanceOf[Array[(VertexId, (String, Double, String))]]) {
            val itera1 = triplet.dstAttr.apply("rec").asInstanceOf[Array[(VertexId, (String, Double, String))]] //取出每个dst顶点上的map中的“rec”键对应的value，类型是：Array[(String,String)],分别代表id和类别:score类型的数组
            val itera2 = itera1.map(x => (x._1, (x._2._1, x._2._2 * triplet.attr, x._2._3)))
            Iterator((triplet.srcId, itera2))
          } else {
            Iterator.empty
          }
        },
      (data1, data2) => data1.++:(data2))
    val t1 = System.currentTimeMillis()
    logger.warn("基于好友的pregel两次迭代用时："+(t1-t0))
    val pointData = g2.vertices.filter(x => x._2.apply("type").asInstanceOf[String].equals("person"))
      .map(x =>
        try {
          if (x._2.apply("rec").isInstanceOf[Map[String, List[(String, Double)]]]) {
            (x._1, (x._2.apply("businessId").asInstanceOf[String], x._2.apply("rec").asInstanceOf[Map[String, List[(String, Double)]]]))
          } else {
            (x._1, (x._2.apply("businessId").asInstanceOf[String], Map[String, List[(String, Double)]]()))
          }
        } catch {
          case ex: NoSuchElementException => (x._1, ("", Map[String, List[(String, Double)]]()))
        })

    pointData
  }

  /*
   * 将基于好友的推荐结果和基于圈子的推荐结果进行合并,并将合并好的数据放入到kafka中
   * 传来的数据格式：Array[(String, Map[String, List[(String, Double)]])]-->Array[(用户的业务id, Map[推荐物品类型, List[(推荐物品业务id, score)]])]
   * 返回的结果格式：Array[(String, String, Map[String, List[(String, Double)]])]-->Array[(命名空间名称, 用户的业务id, Map[推荐物品类型, List[(推荐物品业务id, score)]])]
   * 
   * 处理过程：
   * 1.首先将传来的基于好友的推荐结果和基于圈子的推荐结果合并为一个Array
   * 2.将相同用户id的推荐信息合并为一个map
   * 		(1).将两个推荐结果map先转化为list，然后合并到一起
   * 		(2).对list集合按照类型进行分组
   * 		(3).对分组后内容进行合并和去重
   * 				这里，经过之前的分组，同一个用户的相同类型的推荐结果分到了一组，并组成一个list,所以这里就需要对同一类型的推荐结果组成的list进行处理
   *				list2的数据格式是：Map[String, List[(String, List[(String, Double)])]]-->Map[类型, List[(类型, List[(被推荐物品的业务id, score)])]]
   * 				1.对分组后的由相同类型推荐内容组成的list的数据进行合并，就是将同一种类型的推荐结果(list)合并为一个list
   * 				2.因为合并后的内容是由多个可能存在重复id的被推荐物品组成的，所以这里需要对相同id的数据进行分数累加，并去重
   * 3.将命名空间加入到结果中
   * 4.将结果RDD转化为一个数组
   */
  def combineResult(
    g2: Graph[Map[String, Object], Double],
    nameSpace: String,
    recBasedFriends: RDD[(VertexId, (String, Map[String, List[(String, Double)]]))],
    recBasedCircle: RDD[(VertexId, (String, Map[String, List[(String, Double)]]))]): RDD[(String, String, Map[String, List[(String, Double)]])] = {
    //1.先将两个数组合到一起
    val arr1 = recBasedFriends.++(recBasedCircle)

    //2.将相同用户id的推荐信息(map)合并为一个map,
    //返回结果是;RDD[(String, Map[String, List[(String, Double)]])]-->RDD[(用户业务id, Map[推荐物品类型, List[(推荐物品业务id, Double)]])]
    val arr2 = arr1.reduceByKey((x, y) => (x._1, mapCombine(x._2, y._2)))
    //进行去重,获取每个用户顶点对应的邻居节点id
    val neiborIdForPerson = g2.aggregateMessages[String](
      triplet =>
        triplet.sendToSrc(triplet.dstAttr.apply("businessId").asInstanceOf[String]),
      (x, y) => x + "|" + y,
      TripletFields.All).map(x => (x._1, x._2.split("\\|")))

    //将推荐的结果中过滤掉用户顶点的直接关系顶点
    //返回的结果：RDD[(String, String, Map[String, List[(String, Double)]])]-->RDD[(命名空间名称, 用户的业务id, Map[推荐物品类型, List[(推荐物品业务id, score)]])]
    val recResult = arr2.join(neiborIdForPerson).map { x =>
      //x=>(VertexId, ((String, Map[String, List[(String, Double)]]), Array[String]))-->(用户hashid， ((用户业务id， Map[类型， List[(被推荐物品业务id, score)]]),用户的邻居节点业务id组成的数组))
      val filterData = x._2._1._2.map(y => (y._1, y._2.filter(z => !x._2._2.contains(z._1) && !z._1.equals(x._2._1._1)).sortBy(x => x._2).take(10)))
      //这里讲命名空间传进去
      (nameSpace, x._2._1._1, filterData)
    }
    recResult
  }

  /*
   * 参数代表同一个用户下的基于圈子的推荐信息和基于好友的推荐信息
   * Map[String, List[(String, Double)]]-->Map[type, List[(被推荐物品业务id, score)]]
   * 将两个map进行合并，条件是相同的用户id，对list进行合并，并对合并后的list进行分数累加和去重
   * 返回的是一个新的Map[String, List[(String, Double)]]
   */
  def mapCombine(data1: Map[String, List[(String, Double)]], data2: Map[String, List[(String, Double)]]): Map[String, List[(String, Double)]] = {
    val t1 = System.currentTimeMillis()
    //1.将两个推荐结果map先转化为list，然后合并到一起
    val list1 = data1.toList.++(data2.toList) //List[(String, List[(String, Double)])]
    //2.对list集合按照类型进行分组
    val list2 = list1.groupBy(x => x._1)
    //3.对分组后内容进行合并和去重
    //这里，经过之前的分组，同一个用户的相同类型的推荐结果分到了一组，并组成一个list,所以这里就需要对同一类型的推荐结果组成的list进行处理
    //list2的数据格式是：Map[String, List[(String, List[(String, Double)])]]-->Map[类型, List[(类型, List[(被推荐物品的业务id, score)])]]
    val result = list2.map { x => //x:(String, List[(String, List[(String, Double)])])
      //对分组后的由相同类型推荐内容组成的list的数据进行合并，就是将同一种类型的推荐结果(list)合并为一个list
      //返回值：List[(String, Double)]，代表当前类型下的推荐结果组成的list
      val comData = x._2.map(_._2).reduce((x, y) => x.++(y))
      //因为合并后的内容是由多个可能存在重复id的被推荐物品组成的，所以这里需要对相同id的数据进行分数累加，并去重
      val addScoreData = comData.groupBy(_._1).map(x => (x._1, x._2.map(_._2).reduce((x, y) => x + y))).toList
      (x._1, addScoreData)
    }

    val t2 = System.currentTimeMillis()
    //logger.warn("合并结果用时："+(t2-t1))
    result
  }

}