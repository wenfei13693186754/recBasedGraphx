package com.wdcloud.graphx.jobServer

import scala.util.Try
import org.apache.spark.SparkContext
import com.typesafe.config.Config
import spark.jobserver.SparkJob
import spark.jobserver.SparkJobInvalid
import spark.jobserver.SparkJobValid
import spark.jobserver.SparkJobValidation
import spark.jobserver.NamedRddSupport
import collection.JavaConverters._
import org.apache.spark.graphx.VertexId
import com.wdcloud.graphx.modelTraining.RRT_Engine
import com.wdcloud.graphx.javaUtil.Configuration
import akka.event.slf4j.Logger

/**
 * Spark JobServer测试
 * http://debugo.com/jobserver-project-namedrdd/
 * 前者用于验证（如下面代码验证了input.string中需要有指定的内容），还可以验证HDFS或者其他配置信息。
 * 后者为job的执行代码（需要传入一个SparkContext，同样需要config，config中包含*.conf的信息）
 *
 * NamedRddSupport: 通过继承它，可以实现对缓存的RDD的重用
 */
class RecBasedGraphxServer extends Serializable with SparkJob with NamedRddSupport {
  val logger = Logger(this.getClass.getName)
  override def validate(sc: SparkContext, conf: Config): SparkJobValidation = {
    Try(conf.getString("namespace"))
      .map(x => SparkJobValid)
      .getOrElse(SparkJobInvalid("No namespace config param"))  
  }

  override def runJob(sc: SparkContext, conf: Config): Unit = {
    logger.warn("runJob")
    RRT_Engine.jobserverJob(sc, conf)   
  }
}










