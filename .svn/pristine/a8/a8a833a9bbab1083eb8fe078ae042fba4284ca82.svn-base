package com.wdcloud.graphx.graphOperate

import java.io.Serializable

import scala.Iterator
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.graphx.Edge
import org.apache.spark.graphx.EdgeDirection
import org.apache.spark.graphx.EdgeTriplet
import org.apache.spark.graphx.Graph
import org.apache.spark.graphx.Graph.graphToGraphOps
import org.apache.spark.graphx.TripletFields
import org.apache.spark.graphx.VertexId
import org.apache.spark.rdd.RDD
import org.apache.spark.rdd.RDD.rddToPairRDDFunctions

import com.google.common.hash.Hashing
import com.wdcloud.graphx.unit.DataToJson
import com.wdcloud.graphx.kafka.Producer
import com.wdcloud.graphx.hbase.SparkHbase
import org.apache.hadoop.hbase.HBaseConfiguration
import org.apache.hadoop.hbase.client.HBaseAdmin
import org.apache.hadoop.hbase.client.HTable
import org.apache.hadoop.hbase.client.Put
import org.apache.hadoop.hbase.client.Result
import org.apache.hadoop.hbase.io.ImmutableBytesWritable
import org.apache.hadoop.hbase.mapreduce.TableInputFormat
import org.apache.hadoop.hbase.util.Bytes

import akka.event.slf4j.Logger
import scala.collection.immutable.Seq
import org.apache.hadoop.hbase.client.Get
import org.apache.hadoop.hbase.client.Scan
import com.wdcloud.graphx.unit.PregelUtil

/**
 * 使用spark-graphx实现基于好友、圈子来实现推荐二度好友、圈子、物品
 * 		要求：1.离线的、全量的；
 * 				 2.各种关系基于不同权重进行推荐
 *
 */
object RecBasedGraphx extends Serializable {
  val logger = Logger(this.getClass.getName)
  //def startRec (sc: SparkContext, namespace: String){
  def main(args: Array[String]): Unit = {
    //logger.warn("***************************************************************************namespace: "+namespace)
    val t1 = System.currentTimeMillis()
    //创建图
    val sc = CreateSparkContext.init()
    val cg = new CreateGraph(sc)  
    //集群调用main方法
    //val graph = cg.createGraph(args(0))
    
    //eclipse调用，调错使用
    val graph = CreateGraphxBasedText.createGraph()
    
    //jobserver调用
    //val graph = cg.createGraph(namespace)
    
    val t2 = System.currentTimeMillis()  
    logger.warn("创建图用时：" + (t2 - t1))  
    //******************************推荐*****************************************    
    //基于好友的推荐，包括推荐好友、物品和圈子，返回值类型是;RDD[(String, String, Map[String, List[(String, Double)]])]
    val recBasedFriends = RecCode.recBasedSimUser(graph)
    //迭代结束后将PregelUtil重新赋值为0，为基于圈子的迭代做准备
    PregelUtil.iterNum = 0
    val t3 = System.currentTimeMillis()  
    logger.warn("基于好友推荐用时：" + (t3 - t2))
    //离线的对每个用户基于圈子进行物品、好友和圈子的推荐,返回值是RDD[(String, String, Map[String, List[(String, Double)]])]
    val recBasedCircle = RecCode.recICUForUserBasedCircle(graph)
    val t4 = System.currentTimeMillis()  
    logger.warn("基于圈子推荐用时：" + (t4 - t3))
    //对两种推荐结果进行合并   INFO.LOGINID:112233xyf;
    val recResult = RecCode.combineResult(graph, "g1", recBasedFriends, recBasedCircle)
    //recResult.foreach(x => println("命名空间 "+x._1+" 下的用户："+x._2+" 的推荐结果是："+x._3.mkString(",")))
    val t5 = System.currentTimeMillis()
    logger.warn("合并推荐结果用时：" + (t5 - t4))
    //********************************将结果转化为json格式******************************************
    val dataToJson = new DataToJson()
    //将推荐结果中的对每个用户的推荐结果组成的Map中的list转化为json格式
    //数据格式：Array[(String, String, JSONObject)]-->Array[(表名, 用户业务id, JSONObject)]
    val jsonResult = recResult.collect().map(x => (x._1, x._2, dataToJson.mapToJson(x._3)))
    val t6 = System.currentTimeMillis()
    logger.warn("将推荐结果转化为json用时：" + (t6 - t5))
    //********************************将结果放到kafka中*********************************************
    /*val kafkaProducer = Producer  
    jsonResult.foreach { x =>
      kafkaProducer.sends(namespace+".T_REC_RESULT", x._2, x._3.toString())
    }
    val t7 = System.currentTimeMillis()
    logger.warn("将消息放到kafka中用时：" + (t7 - t6))
    sys.exit()//退出应用
*/  }  
}

