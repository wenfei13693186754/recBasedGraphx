package com.wdcloud.graphx.modelBuild.graph.create

import org.apache.spark.graphx.Graph
import org.apache.spark.graphx.Graph.graphToGraphOps
import org.apache.spark.rdd.RDD
import org.apache.spark._
import com.google.common.hash.Hashing
import com.wdcloud.graphx.javaUtil.TimeOperate
import com.wdcloud.graphx.scalaUtil.CreateSparkContext
import org.apache.spark.graphx.Edge
import org.apache.spark.graphx.EdgeDirection
import com.wdcloud.graphx.javaUtil.Configuration
import com.wdcloud.graphx.modelBuild.graph.GraphModel

/**
 * 读取txt文件中的数据，生成图模型
 */
class CreateGraphModelByTxt extends GraphModel with Serializable{
  
  var conf: Configuration = null
  var userConf: Map[String, String] = null
  /*
   * 创建图
   * Graph[Array[String], Double]   这里创建图使用了Graph类的单例对象的aply构造方法创建，返回的Graph中的Array[String]是vertices的attr的类型
   * Double是Edge上的属性的类型
   */
  def createGraph(sc: SparkContext): Graph[Map[String, Object], Double] = {
    //从内存中读取源数据的路径
    val path = conf.get("data.input.path")

    //通过 .edges 文件计算边，得到两个用户之间的关系 并且计算他们相同特征的个数
    //person_1 person circle_1 circle 1 1453128202076
    val edges = sc.textFile(path+"\\edges.txt").map {
      line =>
      	val row = line.split(" ")
        
  			//生成srcId
  			val srcId = hashId(row(0), row(1))
  			//生成dstId
  			val dstId = hashId(row(2), row(3))
  			//读取行为类型
  			val bhv_type = row(4)
  			val relaScore: Double = bhv_type match {
  			  case "0" => 1.0
			    case "1" => 0.9
		      case "2" => 0.8
	        case "3" => 0.7
          case "4" => 0.6
          case "5" => 0.5
          case "6" => 0.4
          case "7" => 0.3
          case _ => 0
  			}
  			
  			//计算顶点之间亲密度
  			var totalScore: Double = 0
  			
  			if(relaScore == 0.4 ||relaScore == 0.5){//是聊天、浏览
  				//计算交互次数
  			  val communicateNum = row(5).toInt
  			  totalScore = math.log10(relaScore * communicateNum * 1000000 / math.pow(row(5).toLong / 36000000, 1.5) + 1)
  			}else{
  			  totalScore = math.log10(relaScore * 1000000 / math.pow(row(5).toLong / 360000000, 1.5) + 1)
  			}
				Edge(srcId,dstId,totalScore)
    }
    
    //通过.txt文件计算出图的顶点，顶点的一个属性是该顶点所属的类别，是人还是物
    val vertex = sc.textFile(path+"\\users.txt").map {
      line =>
        val arr = line.split(" ")
        val srcId = hashId(arr(0), arr(1))
        //对于圈子作为一个顶点存在的话，使用如下代码
        //将属性添加到map集合中
        //person_1|person girl 25 beijing rose 1 2 邻居id 
        var attr: Map[String, Object] = Map("businessId" -> arr(0), "type" -> arr(1))
        (srcId, attr)
    }
    //利用 fromEdges建立图 
    val graph = Graph(vertex, edges).cache
    //全图操作，每个顶点收集自己邻居顶点id
    val dealGraph = graph.collectNeighborIds(EdgeDirection.Either)
    //将收集到信息的顶点重新加入到原图上，使得图中对应顶点包含自己邻居节点的id这一属性
    val finallyGraph = graph.joinVertices(dealGraph)((id, oldCost, extraCost) => oldCost.+("neiborId" -> extraCost))
    finallyGraph
  }
  
  
  /*
   * 计算user和一度好友之间的亲密度
   * edgeData[(Long, Long, Int, Long)]
   * 				srcId,dstId,communicateNum,time（time代表的是用户之间最近一次交互的时间和当前时间的时间差） 
   * comAvg:用户之间的平均交互次数；
   * 
   * 返回值：RDD[(long,long,Double)]-->(srcId,dstId,score)
   */
  def countCohesion(edgeData: RDD[(Long, Long, Int, Long)], comAvg: Double): RDD[(Long, Long, Double)] = {
    //计算亲密度
    val cohesion = edgeData.map { x =>
      var scoreCom: Double = 0
      var totalScore: Double = 0
      if (comAvg != 0) {
        scoreCom = (x._3 - comAvg) * 0.6 / comAvg
        //时间差的指数作为分母
        totalScore = scoreCom / math.pow(x._4 / 3600000, 1.5)
      } else {
        totalScore = -1.0
      } 
      (x._1, x._2, totalScore)
    }

    cohesion
  }

  def hashId(name: String, str: String):Long = {
    Hashing.md5().hashString(name+""+str).asLong()
  }
}